# Проект "MNIST Classifier"
Данный проект представляет собой простой классификатор для рукописных цифр с использованием набора данных MNIST. Он включает в себя модули для загрузки данных, создания, обучения и оценки модели нейронной сети.

## Описание модели
Модель является сверточной нейронной сетью (Convolutional Neural Network, CNN), присутствие слоев Flatten и Dense является существенным отличием сверточной нейронной сети от полносвязных нейронных сетей.
CNN широко используется для задач обработки изображений, таких как классификация изображений, поскольку она способна автоматически изучать иерархические признаки на разных уровнях абстракции.
Простая сверточная нейронная сеть (CNN), состоящая из слоев Flatten (для преобразования входных изображений в одномерный вектор) и Dense (полносвязные слои для вычисления иерархических признаков и классификации).
Данная архитектура модели была выбрана из-за своей простоты и способности достаточно хорошо решать задачу классификации MNIST, которая является относительно небольшой и относительно простой задачей для нейронных сетей.

Данная модель нейронной сети представляет собой простую архитектуру с тремя слоями:

- Входной слой Flatten: Слой для преобразования входных изображений размера 28x28 пикселей в одномерный вектор с 784 элементами.

- Скрытый слой Dense(128, activation='relu'): Состоит из 128 нейронов с функцией активации ReLU (Rectified Linear Unit), что позволяет добавить нелинейность в модель.

- Еще один скрытый слой Dense(64, activation='relu'): Состоит из 64 нейронов с функцией активации ReLU.

- Выходной слой Dense(10, activation='softmax'): Состоит из 10 нейронов с функцией активации Softmax, которая преобразует числовые значения в вероятности принадлежности каждого из 10 классов (цифры от 0 до 9).

## Настройка и обучение модели
- Загрузка данных   
Для обучения и тестирования модели используется набор данных MNIST, который представляет изображения рукописных цифр и соответствующие им метки классов.

- Предобработка данных  
Все значения пикселей изображений нормализуются, чтобы они находились в диапазоне от 0 до 1. Метки классов преобразуются в one-hot векторы с помощью функции to_categorical, чтобы соответствовать формату выходного слоя.

- Обучение модели  
Модель обучается с использованием оптимизатора "adam" и функции потерь "categorical_crossentropy". Для обучения модели задается 5 эпох (одна эпоха - это один проход по всему набору данных) и размер пакета обучения (batch_size) равный 32. Всего обучение проходит за несколько итераций с использованием метода обратного распространения ошибки.

- Оценка производительности модели  
После обучения модель оценивается на тестовых данных для вычисления точности и потери. Точность (accuracy) показывает, как хорошо модель классифицирует изображения, а потеря (loss) показывает, насколько хорошо предсказанные значения соответствуют истинным меткам.

## Параметры модели
В данном проекте были выбраны следующие параметры:

- Архитектура модели: простая нейронная сеть с тремя плотными слоями.
- Функция активации: ReLU (для скрытых слоев) и Softmax (для выходного слоя).
- Оптимизатор: "adam" - эффективный оптимизатор с адаптивной скоростью обучения.
- Функция потерь: "categorical_crossentropy" - подходящая функция потерь для многоклассовой классификации.
- Количество эпох: 5 - количество проходов по всему обучающему набору данных.
- Размер пакета обучения (batch_size): 32 - количество примеров, обрабатываемых за одну итерацию обучения.
- Выбранные параметры обеспечивают достаточно хорошую производительность для данной простой задачи классификации MNIST.

## Запуск проекта
- Убедитесь, что у вас установлены необходимые библиотеки, включая TensorFlow и Keras. Если нет, установите их с помощью pipenv install.

- Запустите файл main.py для обучения модели и оценки ее производительности.

## Отчет о производительности
После завершения обучения и оценки модели, в консоли будет выведен отчет о производительности, включающий точность (accuracy) и потерю (loss) на тестовых данных.